{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import lyricsgenius\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84132864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secrets import *\n",
    "cwd = os.getcwd()\n",
    "file_name = \"data/MacMiller_AD.csv\"\n",
    "file_path = os.path.join(cwd, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b0a6c3",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lyricsgenius.Genius(GENIUS_ACCESS_TOKEN)\n",
    "genius.verbose = False # Turn off status messages\n",
    "genius.remove_section_headers = True # Remove section headers (e.g. [Chorus]) from lyrics when searching\n",
    "genius.skip_non_songs = False # Include hits thought to be non-songs (e.g. track lists)\n",
    "genius.excluded_terms = [\"(Remix)\", \"(Live)\", \"Remix\"] # Exclude songs with these words in their title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Mac_AD():\n",
    "    artists = ['Mac Miller']\n",
    "    artist_df = pd.DataFrame()\n",
    "    albums = ['Blue Slide Park', 'Watching Movies with the Sound Off', 'Faces',\n",
    "             'GO:OD AM', 'The Divine Feminine', 'Swimming', 'Circles',\n",
    "             'K.I.D.S.', 'Best Day Ever', 'I Love Life, Thank You', 'Macadelic', 'Delusional Thomas',\n",
    "             'You'] #'Live from Space',\n",
    "\n",
    "    for album_name in tqdm(albums):\n",
    "\n",
    "        if album_name not in ['You', 'Delusional Thomas']:\n",
    "            album = genius.search_album(album_name, artists[0])\n",
    "        elif album_name == 'You':\n",
    "            album = genius.search_album(album_name, 'Larry Lovestein & The Velvet Revival')\n",
    "        elif album_name == 'Delusional Thomas':\n",
    "            album = genius.search_album(album_name, 'Delusional Thomas')\n",
    "        assert len(album.tracks) != 0, 'Empty album'\n",
    "\n",
    "        d = []\n",
    "        i=0\n",
    "        for i in range (len(album.tracks)):\n",
    "            if \"remix\" in album.tracks[i].song.title.lower():\n",
    "                break\n",
    "            else:\n",
    "                d.append(\n",
    "                    {\n",
    "                        'artist': (album.tracks[i].song.artist),\n",
    "                        'album': (album.name),\n",
    "                        'release_date' : (album.release_date_components.strftime('%Y-%m-%d')),\n",
    "                        'track_no' : (album.tracks[i].number),\n",
    "                        'title': (album.tracks[i].song.title),\n",
    "                        'lyrics': (album.tracks[i].song.lyrics),\n",
    "                        'art': (album.cover_art_url),\n",
    "                        'url': (album.tracks[0].song.url)\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        album_df = pd.DataFrame(d)\n",
    "        album_df['lyrics'] = album_df['lyrics'].replace(to_replace ='\\[.*?\\]', value = '', regex = True)\n",
    "        album_df['lyrics'] = album_df['lyrics'].replace(to_replace =r'^.*?Lyrics', value = '', regex = True)\n",
    "        album_df['lyrics'] = album_df['lyrics'].replace(to_replace = r'\\d{2}Embed$', value = '', regex = True)\n",
    "        album_df['lyrics'] = album_df['lyrics'].replace(to_replace = r'\\d{1}Embed$', value = '', regex = True)\n",
    "        album_df['track_no'] = album_df['track_no'].astype(int)\n",
    "\n",
    "        artist_df = pd.concat([artist_df, album_df]).reset_index(drop=True)\n",
    "        assert artist_df[artist_df['lyrics'].isna()].shape[0] == 0\n",
    "\n",
    "    artist_df = artist_df[~artist_df['title'].str.contains('live|remix', case=False)].reset_index(drop=True)\n",
    "    artist_df = artist_df.sort_values(by=['release_date','track_no']).reset_index(drop=True)\n",
    "    artist_df.to_csv(\"data/MacMiller_AD.csv\", index=False)\n",
    "    \n",
    "    return artist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2b0c0",
   "metadata": {},
   "source": [
    "### GPT Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c9a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=OPEN_AI_TOKEN,)\n",
    "cwd = os.getcwd()\n",
    "file_name = \"data/GPT_Results.csv\"\n",
    "file_path = os.path.join(cwd, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3127c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_word(theme_list):\n",
    "    return [theme.split()[0] if ' ' in theme else theme for theme in theme_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc838f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(file_path):\n",
    "    df = pd.read_csv(\"data/MacMiller_AD.csv\")\n",
    "    df['lyrics'] = df['lyrics'].astype(str)\n",
    "    df['lyrics'] = df['lyrics'].replace('\\n', ' ')\n",
    "    df['score'] = \"\"\n",
    "    df['themes'] = \"\"\n",
    "\n",
    "    df = df.loc[df['lyrics'] != 'nan'].reset_index(drop=True)\n",
    "    # Profile of the person who would write these lyrics\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        lyrics = row['lyrics']\n",
    "\n",
    "        completion = openai_client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": '''You are skilled at understanding the nuance of lyrics, \n",
    "            especially hip-hop. This means understanding metaphor and slang and knowing if something is \n",
    "            said positively or negatively. I will send you lyrics from a song. I would like you to respond \n",
    "            with a scaling of sentiment from 1 as most negative to 10 as most positive. Followed by your \n",
    "            numerical rating, you'll write // and 5 individual words expressing the overall theme of \n",
    "            feeling conveyed by the lyrics. Your final output should be a number // 5 comma separated words'''},\n",
    "\n",
    "            {\"role\": \"user\", \"content\": lyrics}\n",
    "          ]\n",
    "        )\n",
    "\n",
    "        rating = completion.choices[0].message.content.split(\"//\")[0].strip()\n",
    "        themes = completion.choices[0].message.content.split(\"//\")[1].strip().strip(\".\").split(\",\")\n",
    "\n",
    "        df.at[index, 'score'] = rating\n",
    "        df.at[index, 'themes'] = themes\n",
    "\n",
    "    df.loc[df['score'] == 'Sentiment: 7', 'score'] = '7'\n",
    "    df['score'] = df['score'].astype(float)\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        sublist = row['themes']\n",
    "\n",
    "        for i in range(len(sublist)):\n",
    "            sublist[i] = ''.join(char for char in sublist[i] if not char.isdigit())\n",
    "            sublist[i] = sublist[i].strip()\n",
    "\n",
    "        row['themes'] = sublist\n",
    "\n",
    "    # Apply the function to the 'themes' column\n",
    "    df['themes'] = df['themes'].apply(extract_first_word)\n",
    "\n",
    "    df.to_csv(\"data/GPT_Results.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9acb7",
   "metadata": {},
   "source": [
    "### Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/GPT_Results.csv\")\n",
    "albums = df[['album', 'score', 'themes']].reset_index(drop=True)\n",
    "album_score = albums.groupby(['album']).agg(score = (\"score\",\"mean\")).reset_index()\n",
    "\n",
    "for index, row in albums.iterrows():\n",
    "    x = albums.iloc[index, 2]\n",
    "    x = x[1:-1]\n",
    "    x = x.replace('\\'', '')\n",
    "    albums.iloc[index, 2] = x\n",
    "    \n",
    "album_theme = albums.groupby(['album'])['themes'].apply(','.join).reset_index()\n",
    "\n",
    "albums = album_score.merge(album_theme, on=['album'])\n",
    "album_info = df[['album','release_date','art']].drop_duplicates().reset_index(drop=True)\n",
    "albums = albums.merge(album_info, on=['album'])\n",
    "albums.to_csv(\"data/MM_Albums_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51221432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/GPT_Results.csv\")\n",
    "for index, row in df.iterrows():\n",
    "    x = df.iloc[index, 9]\n",
    "    x = x[1:-1]\n",
    "    x = x.replace('\\'', '')\n",
    "    df.iloc[index, 9] = x\n",
    "\n",
    "df.to_csv(\"data/MM_AllSongs_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b48e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "albums['persona'] = ''\n",
    "albums['ai_image'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793e36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/MM_Albums_sentiment_with_DallE.csv\"\n",
    "file_path = os.path.join(cwd, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166933b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(file_path):\n",
    "    for index, row in tqdm(albums.iterrows(), total=len(albums), desc=\"Processing rows\"):\n",
    "        if row['persona'] == '':\n",
    "            themes = row['themes']\n",
    "            album_name = row['album']\n",
    "\n",
    "            any_image_prompt = 'generate an image using the following list of thematic words. Try to encapsulate the overall concept in a picture: '\n",
    "            person_prompt = 'I will share a group of thematic words. Generate the image of a person that fits the overall theme of the group of words: '\n",
    "\n",
    "            response = openai_client.images.generate(\n",
    "              model=\"dall-e-3\",\n",
    "              prompt=f\"{person_prompt} {themes}\",\n",
    "              size=\"1024x1024\",\n",
    "              quality=\"standard\",\n",
    "              n=1,\n",
    "            )\n",
    "\n",
    "            image_url = response.data[0].url\n",
    "\n",
    "            albums.at[index, 'persona'] = image_url\n",
    "\n",
    "            im = Image.open(requests.get(image_url, stream=True).raw)\n",
    "            im = im.save(f\"data/persona_img/{album_name}_Persona.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb852a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(file_path):\n",
    "    for index, row in tqdm(albums.iterrows(), total=len(albums), desc=\"Processing rows\"):\n",
    "        if row['ai_image'] == '':\n",
    "            themes = row['themes']\n",
    "            album_name = row['album']\n",
    "\n",
    "            any_image_prompt = 'generate an image using the following list of thematic words. Try to encapsulate the overall concept in a picture: '\n",
    "            person_prompt = 'I will share a group of thematic words. Generate the image of a person that fits the overall theme of the group of words: '\n",
    "\n",
    "            response = openai_client.images.generate(\n",
    "              model=\"dall-e-3\",\n",
    "              prompt=f\"{any_image_prompt} {themes}\",\n",
    "              size=\"1024x1024\",\n",
    "              quality=\"standard\",\n",
    "              n=1,\n",
    "            )\n",
    "\n",
    "            image_url = response.data[0].url\n",
    "\n",
    "            albums.at[index, 'ai_image'] = image_url\n",
    "\n",
    "            im = Image.open(requests.get(image_url, stream=True).raw)\n",
    "            im = im.save(f\"data/ai_img/{album_name}_Img.jpg\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a333179",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(file_path):\n",
    "    albums.to_csv(\"data/MM_Albums_sentiment_with_DallE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedf0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/MM_Albums_sentiment_with_DallE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4eab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1+1 == 3:\n",
    "    df['album_theme'] = ''\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        lyrics = row['themes']\n",
    "\n",
    "        completion = openai_client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": '''I will pass you a list of words, each of which represents the theme \n",
    "            of a body of art. I want you to consolidate the list into 5 words. Your output should be solely 5 words \n",
    "            separated by commas.'''},\n",
    "\n",
    "            {\"role\": \"user\", \"content\": lyrics}\n",
    "          ]\n",
    "        )\n",
    "\n",
    "        album_theme = completion.choices[0].message.content\n",
    "        df.at[index, 'album_theme'] = album_theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b58e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1+1 == 3:\n",
    "    df['album_summary'] = ''\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        lyrics = row['themes']\n",
    "\n",
    "        completion = openai_client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": '''I will pass you a list of words, each of which represents the theme \n",
    "            of an album. Respond with \"The ideal place to listen to this record would be: \" and then share \n",
    "            the best place to listen to that album. Limit responses to one sentence.'''},\n",
    "\n",
    "            {\"role\": \"user\", \"content\": lyrics}\n",
    "          ]\n",
    "        )\n",
    "\n",
    "        album_summary = completion.choices[0].message.content\n",
    "        df.at[index, 'album_summary'] = album_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1+1 == 3:\n",
    "    df.to_csv(\"data/MM_Albums_sentiment_with_DallE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9e1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/MM_AllSongs_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11baafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1+1 == 3:\n",
    "    df['death_counter'] = ''\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        lyrics = row['lyrics']\n",
    "\n",
    "        completion = openai_client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "\n",
    "          messages=[\n",
    "            {\"role\": \"system\", \"content\": '''I will pass you song lyrics. I want you to count the number \n",
    "            of times that death or death-adjacent themes are mentioned. This should include suicide, homicide, \n",
    "            heaven, hell, etc. Pay attention for slang that may indicate death. You should only return a number, no other text.'''},\n",
    "\n",
    "            {\"role\": \"user\", \"content\": lyrics}\n",
    "          ]\n",
    "        )\n",
    "\n",
    "        death_count = completion.choices[0].message.content\n",
    "        df.at[index, 'death_counter'] = death_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1+1 == 3:\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "        text = row['death_counter']\n",
    "        new_text = re.sub('\\D', '', text)\n",
    "        df.at[index, 'death_counter'] = new_text\n",
    "\n",
    "    df['death_counter'] = df['death_counter'].astype(int)\n",
    "    album_death_counter = df.groupby(['album'])['death_counter'].sum().reset_index()\n",
    "    album_death_counter.to_csv(\"data/album_death_counter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0b912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0cd2cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877e11d",
   "metadata": {},
   "source": [
    "### Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e532791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# from nltk.corpus import stopwords\n",
    "# from textblob import TextBlob\n",
    "# from textblob import Word\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# pd.options.display.max_colwidth = 17\n",
    "\n",
    "# def vader_analysis():\n",
    "#     '''\n",
    "#     '''\n",
    "#     analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#     artist_df = pd.read_csv(\"data/MacMiller_AD.csv\")\n",
    "#     mac = artist_df.copy()\n",
    "#     mac['lyrics'] = mac['lyrics'].astype(str)\n",
    "#     mac['lyrics'] = mac['lyrics'].replace('\\n', ' ')\n",
    "\n",
    "#     # 2) Basic Pre-Processing\n",
    "#     mac['polarity'] = mac['lyrics'].apply(lambda x: TextBlob(x).sentiment.polarity*100)\n",
    "#     mac['polarity'] = mac['polarity'].round(3)\n",
    "\n",
    "#     mac['subjectivity'] = mac['lyrics'].apply(lambda x: TextBlob(x).sentiment.subjectivity*100)\n",
    "#     mac['subjectivity'] = mac['subjectivity'].round(3)\n",
    "\n",
    "#     mac['Positive_Score'] = mac['lyrics'].apply(lambda x: analyzer.polarity_scores(x)['pos']*100)\n",
    "#     mac['Negative_Score'] = mac['lyrics'].apply(lambda x: analyzer.polarity_scores(x)['neg']*100)\n",
    "#     mac['Neutral_Score'] = mac['lyrics'].apply(lambda x: analyzer.polarity_scores(x)['neu']*100)\n",
    "#     mac['Compound_Score'] = mac['lyrics'].apply(lambda x: analyzer.polarity_scores(x)['compound']*100)\n",
    "#     mac = mac.sort_values('Compound_Score', ascending=False)\n",
    "\n",
    "#     # Calculate album-level metrics\n",
    "#     album_metrics = mac.groupby(['album']).agg({'Positive_Score': 'mean', \n",
    "#                                                 'Negative_Score': 'mean', \n",
    "#                                                 'Neutral_Score': 'mean', \n",
    "#                                                 'Compound_Score': 'mean'})\n",
    "\n",
    "#     # Calculate overall average\n",
    "#     overall_average = mac[['Positive_Score', 'Negative_Score', 'Neutral_Score', 'Compound_Score']].mean()\n",
    "\n",
    "#     # Calculate relative difference\n",
    "#     relative_difference = (album_metrics - overall_average) / overall_average\n",
    "\n",
    "#     compound_sort = album_metrics.sort_values(by=['Compound_Score'], ascending = False)\n",
    "#     positive_sort = album_metrics.sort_values(by=['Positive_Score'], ascending = False)\n",
    "#     negative_sort = album_metrics.sort_values(by=['Negative_Score'], ascending = False)\n",
    "#     neutral_sort = album_metrics.sort_values(by=['Neutral_Score'], ascending = False)\n",
    "\n",
    "#     album_metrics['Variability'] = abs(album_metrics['Positive_Score'] - album_metrics['Negative_Score'])\n",
    "\n",
    "#     mac.to_csv(f\"data/MM_AllSongs_sentiment.csv\", index = False)\n",
    "#     album_metrics = album_metrics.reset_index()\n",
    "#     album_metrics.to_csv(f\"data/MM_Albums_sentiment.csv\", index = False)\n",
    "\n",
    "#     return album_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eeb935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
